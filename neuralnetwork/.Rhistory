X <- as.matrix(diabetes[, 1:8])
X <- as.matrix(diabetes[, 1:8])
library(readr)
diabetes <- read_csv("diabetes.csv")
View(diabetes)
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 20
alpha <- 0.2
models <- list()
errors <- list()
for (restart in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
preds <- vector()
for (i in 1:10) {
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
perceptron <- function(X,Y,T,alpha){
N = nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M = ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X = cbind(X, rep(-1, N))
# INICIALIA??O ALEATORIA DOS PESOS DA REDE COM VALORES ALEAT?RIOS ENTRE -1 E 1
wt = as.matrix(runif(M+1,-1,1))
list_sse = cbind()
# CICLO DE APRENDIZADO
for (t in 1:T){
all_erros = cbind()
for (j in 1:N){
# EXEMPLO ATUAL
xj = X[j,]
yj = Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s = t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUN??O DE ATIVA??O SIGMOID
fj = 1/(1+exp(-s))
# CALCULO DO ERRO
ej = yj - fj
all_erros = cbind(all_erros,ej)
# REGRA DELTA
wt = wt + as.numeric(alpha*ej) * xj
} # TERMINO DO CICLO
sse_t = sum(all_erros^2)
writeLines(sprintf("Itera??o: %d. Erro: %.2f.",t,sse_t))
list_sse = cbind(list_sse,sse_t)  # SOMA ERROs QUADRADOS BNA ITERACAO t
}  # TERMINO DO APRENDIZADO
return(list(modelo = wt, erros = list_sse, sse = list_sse[T]))
}
# DADOS DE TREINAMENTO PARA  PORTA LOGICA 'AND'
X = matrix(0,4,2)
X[1,] = c(0,0)
X[2,] = c(0,1)
X[3,] = c(1,0)
X[4,] = c(1,1)
Y =  as.matrix(c(0,0,0,1))
# TREINAMENTO DO MODELO DURANTE 50 CICLOS E TAXA DE 0.2
T = 100
alpha = 0.2
modelo = perceptron(X,Y,T,alpha)
# PLOT DOS ERROS POR ITERA??O
plot(1:T,modelo$erros,type = "l",xlab = "Iteration",ylab = "Sum of Square Errors")
# FUN??O PARA TREINAMENTO DO MODELO DURANTE T ITERA??ES
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 20
alpha <- 0.2
models <- list()
errors <- list()
for (restart in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
preds <- vector()
for (i in 1:10) {
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
# Encontre a melhor reinicialização (menor erro)
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
# Visualizar as previsões
cat("Previsões:", preds, "\n")
cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
cat("Erro do melhor modelo:", best_error, "\n")
#Resultado do código rodado
#Previsões: 0 0 1 0 1 0 0 1 1 0
#> cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
#Melhor modelo (reinicialização 3 ): 238.9969 11.43141 -71.69301 -53.83062 28.79127 10.08737 24.79444 -39.82843 116.1938
#> cat("Erro do melhor modelo:", best_error, "\n")
#Erro do melhor modelo: 0.4557292

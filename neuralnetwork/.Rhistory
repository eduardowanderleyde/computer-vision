X <- as.matrix(diabetes[, 1:8])
X <- as.matrix(diabetes[, 1:8])
library(readr)
diabetes <- read_csv("diabetes.csv")
View(diabetes)
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 20
alpha <- 0.2
models <- list()
errors <- list()
for (restart in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
preds <- vector()
for (i in 1:10) {
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
perceptron <- function(X,Y,T,alpha){
N = nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M = ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X = cbind(X, rep(-1, N))
# INICIALIA??O ALEATORIA DOS PESOS DA REDE COM VALORES ALEAT?RIOS ENTRE -1 E 1
wt = as.matrix(runif(M+1,-1,1))
list_sse = cbind()
# CICLO DE APRENDIZADO
for (t in 1:T){
all_erros = cbind()
for (j in 1:N){
# EXEMPLO ATUAL
xj = X[j,]
yj = Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s = t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUN??O DE ATIVA??O SIGMOID
fj = 1/(1+exp(-s))
# CALCULO DO ERRO
ej = yj - fj
all_erros = cbind(all_erros,ej)
# REGRA DELTA
wt = wt + as.numeric(alpha*ej) * xj
} # TERMINO DO CICLO
sse_t = sum(all_erros^2)
writeLines(sprintf("Itera??o: %d. Erro: %.2f.",t,sse_t))
list_sse = cbind(list_sse,sse_t)  # SOMA ERROs QUADRADOS BNA ITERACAO t
}  # TERMINO DO APRENDIZADO
return(list(modelo = wt, erros = list_sse, sse = list_sse[T]))
}
# DADOS DE TREINAMENTO PARA  PORTA LOGICA 'AND'
X = matrix(0,4,2)
X[1,] = c(0,0)
X[2,] = c(0,1)
X[3,] = c(1,0)
X[4,] = c(1,1)
Y =  as.matrix(c(0,0,0,1))
# TREINAMENTO DO MODELO DURANTE 50 CICLOS E TAXA DE 0.2
T = 100
alpha = 0.2
modelo = perceptron(X,Y,T,alpha)
# PLOT DOS ERROS POR ITERA??O
plot(1:T,modelo$erros,type = "l",xlab = "Iteration",ylab = "Sum of Square Errors")
# FUN??O PARA TREINAMENTO DO MODELO DURANTE T ITERA??ES
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 20
alpha <- 0.2
models <- list()
errors <- list()
for (restart in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
preds <- vector()
for (i in 1:10) {
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
# Encontre a melhor reinicialização (menor erro)
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
# Visualizar as previsões
cat("Previsões:", preds, "\n")
cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
cat("Erro do melhor modelo:", best_error, "\n")
#Resultado do código rodado
#Previsões: 0 0 1 0 1 0 0 1 1 0
#> cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
#Melhor modelo (reinicialização 3 ): 238.9969 11.43141 -71.69301 -53.83062 28.79127 10.08737 24.79444 -39.82843 116.1938
#> cat("Erro do melhor modelo:", best_error, "\n")
#Erro do melhor modelo: 0.4557292
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 1000
alpha <- 0.001
models <- list()
errors <- list()
preds <- vector() #o vetor fora para salvar a cada reinicialização
for (restart in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
for (i in 1:N) { #N é o número de colunas
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
#salvando os modelos no vetor
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 10
alpha <- 0.001
models <- list()
errors <- list()
preds <- vector() #o vetor fora para salvar a cada reinicialização
for (restart in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
for (i in 1:N) { #N é o número de colunas
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
#salvando os modelos no vetor
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
# Encontre a melhor reinicialização (menor erro)
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
# Visualizar as previsões
cat("Previsões:", preds, "\n")
cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
cat("Erro do melhor modelo:", best_error, "\n")
#Resultado do código rodado
# cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
# Melhor modelo foi a (reinicialização 1 ): com valores de 1.505233 0.1842062 -0.443606 -0.2335423 0.1725539 0.01922837 0.3058519 -0.2764221 0.2215401
# cat("Erro do melhor modelo:", best_error, "\n")
# Menor erro do melhor modelo: 0.3645833
perceptron <- function(X, Y, T, alpha) {
N <- nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M <- ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X <- cbind(X, rep(-1, N))
best_model <- NULL
best_sse <- Inf
for (restart in 1:20) {
# INICIALIZAÇÃO ALEATÓRIA DOS PESOS DA REDE COM VALORES ALEATÓRIOS ENTRE -1 E 1
wt <- matrix(runif(M + 1, -1, 1))
list_sse <- numeric(T)
# CICLO DE APRENDIZADO
for (t in 1:T) {
all_errors <- numeric(N)
for (j in 1:N) {
# EXEMPLO ATUAL
xj <- X[j, ]
yj <- Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s <- t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUNÇÃO DE ATIVAÇÃO SIGMOID
fj <- 1 / (1 + exp(-s))
# CALCULO DO ERRO
ej <- yj - fj
all_errors[j] <- ej
# REGRA DELTA
wt <- wt + as.numeric(alpha * ej) * xj
}
sse_t <- sum(all_errors^2)
list_sse[t] <- sse_t
cat(sprintf("Reinicialização: %d. Iteração: %d. Erro: %.2f.\n", restart, t, sse_t))
if (sse_t < best_sse) {
best_sse <- sse_t
best_model <- wt
}
}
}
return(list(modelo = best_model, erros = list_sse, sse = best_sse))
}
perceptron <- function(X, Y, T, alpha) {
N <- nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M <- ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X <- cbind(X, rep(-1, N))
best_model <- NULL
best_sse <- Inf
for (restart in 1:20) {
# INICIALIZAÇÃO ALEATÓRIA DOS PESOS DA REDE COM VALORES ALEATÓRIOS ENTRE -1 E 1
wt <- matrix(runif(M + 1, -1, 1))
list_sse <- numeric(T)
# CICLO DE APRENDIZADO
for (t in 1:T) {
all_errors <- numeric(N)
for (j in 1:N) {
# EXEMPLO ATUAL
xj <- X[j, ]
yj <- Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s <- t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUNÇÃO DE ATIVAÇÃO SIGMOID
fj <- 1 / (1 + exp(-s))
# CALCULO DO ERRO
ej <- yj - fj
all_errors[j] <- ej
# REGRA DELTA
wt <- wt + as.numeric(alpha * ej) * xj
}
sse_t <- sum(all_errors^2)
list_sse[t] <- sse_t
cat(sprintf("Reinicialização: %d. Iteração: %d. Erro: %.2f.\n", restart, t, sse_t))
if (sse_t < best_sse) {
best_sse <- sse_t
best_model <- wt
}
}
}
return(list(modelo = best_model, erros = list_sse, sse = best_sse))
}
perceptron <- function(X, Y, T, alpha) {
N <- nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M <- ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X <- cbind(X, rep(-1, N))
best_model <- NULL
best_sse <- Inf
for (restart in 1:20) {
# INICIALIZAÇÃO ALEATÓRIA DOS PESOS DA REDE COM VALORES ALEATÓRIOS ENTRE -1 E 1
wt <- matrix(runif(M + 1, -1, 1))
list_sse <- numeric(T)
# CICLO DE APRENDIZADO
for (t in 1:T) {
all_errors <- numeric(N)
for (j in 1:N) {
# EXEMPLO ATUAL
xj <- X[j, ]
yj <- Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s <- t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUNÇÃO DE ATIVAÇÃO SIGMOID
fj <- 1 / (1 + exp(-s))
# CALCULO DO ERRO
ej <- yj - fj
all_errors[j] <- ej
# REGRA DELTA
wt <- wt + as.numeric(alpha * ej) * xj
}
sse_t <- sum(all_errors^2)
list_sse[t] <- sse_t
cat(sprintf("Reinicialização: %d. Iteração: %d. Erro: %.2f.\n", restart, t, sse_t))
if (sse_t < best_sse) {
best_sse <- sse_t
best_model <- wt
}
}
}
return(list(modelo = best_model, erros = list_sse, sse = best_sse))
}
perceptron <- function(X, Y, T, alpha) {
N <- nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M <- ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X <- cbind(X, rep(-1, N))
best_model <- NULL
best_sse <- Inf
for (restart in 1:20) {
# INICIALIZAÇÃO ALEATÓRIA DOS PESOS DA REDE COM VALORES ALEATÓRIOS ENTRE -1 E 1
wt <- matrix(runif(M + 1, -1, 1))
list_sse <- numeric(T)
# CICLO DE APRENDIZADO
for (t in 1:T) {
all_errors <- numeric(N)
for (j in 1:N) {
# EXEMPLO ATUAL
xj <- X[j, ]
yj <- Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s <- t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUNÇÃO DE ATIVAÇÃO SIGMOID
fj <- 1 / (1 + exp(-s))
# CALCULO DO ERRO
ej <- yj - fj
all_errors[j] <- ej
# REGRA DELTA
wt <- wt + as.numeric(alpha * ej) * xj
}
sse_t <- sum(all_errors^2)
list_sse[t] <- sse_t
cat(sprintf("Reinicialização: %d. Iteração: %d. Erro: %.2f.\n", restart, t, sse_t))
if (sse_t < best_sse) {
best_sse <- sse_t
best_model <- wt
}
}
}
return(list(modelo = best_model, erros = list_sse, sse = best_sse))
}
perceptron <- function(X, Y, T, alpha) {
N <- nrow(X)  # NUMERO DE EXEMPLOS DE TREINAMENTO
M <- ncol(X)
# TRANSFORMAR DADOS DE TREINAMENTO PARA CONSIDERAR O BIAS COMO UM PESO
X <- cbind(X, rep(-1, N))
T <- 10
best_model <- NULL
best_sse <- Inf
for (restart in 1:20) {
# INICIALIZAÇÃO ALEATÓRIA DOS PESOS DA REDE COM VALORES ALEATÓRIOS ENTRE -1 E 1
wt <- matrix(runif(M + 1, -1, 1))
list_sse <- numeric(T)
# CICLO DE APRENDIZADO
for (t in 1:T) {
all_errors <- numeric(N)
for (j in 1:N) {
# EXEMPLO ATUAL
xj <- X[j, ]
yj <- Y[j]
# CALCULO DA SOMA ACUMULADA DOS PESOS
s <- t(wt) %*% xj
# CALCULO DA SAIDA DO PECEPTRON COM FUNÇÃO DE ATIVAÇÃO SIGMOID
fj <- 1 / (1 + exp(-s))
# CALCULO DO ERRO
ej <- yj - fj
all_errors[j] <- ej
# REGRA DELTA
wt <- wt + as.numeric(alpha * ej) * xj
}
sse_t <- sum(all_errors^2)
list_sse[t] <- sse_t
cat(sprintf("Reinicialização: %d. Iteração: %d. Erro: %.2f.\n", restart, t, sse_t))
if (sse_t < best_sse) {
best_sse <- sse_t
best_model <- wt
}
}
}
return(list(modelo = best_model, erros = list_sse, sse = best_sse))
}
# Converter para matrizes
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 10
alpha <- 0.001
models <- list()
errors <- list()
preds <- vector()
for (restart in 1:20) {
preds <- vector()
modelo <- perceptron(X, Y, T, alpha)
wt <- modelo$modelo
N <- nrow(X)
for (i in 1:N) {
x <- c(X[i, ], -1)
s <- t(wt) %*% x
fj <- 1 / (1 + exp(-s))
preds <- c(preds, ifelse(fj >= 0.5, 1, 0))
}
error <- sum(preds != Y) / N
models[[restart]] <- wt
errors[[restart]] <- error
cat("Reinicialização:", restart, " - Erro:", error, "\n")
}
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
cat("Previsões:", preds, "\n")
cat("Melhor modelo (reinicialização", best_index, "):", best_model, "\n")
cat("Erro do melhor modelo:", best_error, "\n")
for (t in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
models[[t]] <- modelo$modelo
errors = cbind(errors,modelo$sse)
}
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
print(best_index,best_model,best_error)
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
print(best_index,best_model,best_error)
# Converter para matrizes
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 10
alpha <- 0.001
models <- list()
errors <- cbind()
for (t in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
models[[t]] <- modelo$modelo
errors = cbind(errors,modelo$sse)
}
for (t in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
models[[t]] <- modelo$modelo
errors = cbind(errors,modelo$sse)
}
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
print(best_index,best_model,best_error)
# Converter para matrizes
X <- as.matrix(diabetes[, 1:8])
Y <- diabetes$class
Y <- as.factor(Y)
Y <- as.numeric(Y) - 1
T <- 10
alpha <- 0.001
models <- list()
errors <- cbind()
for (t in 1:20) {
modelo <- perceptron(X, Y, T, alpha)
models[[t]] <- modelo$modelo
errors = cbind(errors,modelo$sse)
}
best_index <- which.min(errors)
best_model <- models[[best_index]]
best_error <- errors[[best_index]]
print(best_index)
print(best_model)
print(best_error)
#conferindo
print(errors[15]==min(errors))
